P{Your model has been found to disproportionately decline the parole requests of Maori inmates [2]. As your model uses Neural Network, a black-box technique, the bias is going to be difficult to identify within the model.

What would you like to do?}

C{
  N{Manually debug}
  O{After weeks of effort and a host of costs to your employer, you identify the culprit. A feature is categorically dividing inmates based on race, despite 'race' not being a feature. You remove the feature.}
  Q{}
  R{generic_at_risk}
}

C{
  N{Post-hoc explainability}
  O{You use CERTIFAI, a tool built by Sharma et al. to generate counterfactuals [1]. These are artificial datapoints which have features as close to an actual instance, but which gain the opposite result.

You identify the culprit. A single feature is categorically dividing inmates based on race, despite 'race' not being a feature. You remove the feature.}
  Q{}
  R{}
}

C{
  N{Ignore the issue}
  O{You elect not to change the model.}
  Q{prison_bias_fail}
  R{}
}

Q{}
R{}